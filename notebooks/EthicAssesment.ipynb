{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "The data science team has addressed the earlier ethical issues in their analysis and has built their algorithm into an application, which takes in an applicant's data and outputs the estimated likelihood of default. The bank rolls out this application across various bank branches. Which set of ethical concerns is most relevant at this phase?\n",
    "\n",
    "* C1: Missing perspectives, C2: Dataset bias, C3: Honest representation\n",
    "    * C.1 Missing perspectives: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "    * C.2 Dataset bias: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "    * C.3 Honest representation: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "* **E1: Redress, E2: Roll back, E3: Concept drift**\n",
    "    * E.1 Redress: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "    * E.2 Roll back: Is there a way to turn off or roll back the model in production if necessary?\n",
    "    * E.3 Concept drift: Do we test and monitor for concept drift to ensure the model remains fair over time?\n",
    "\n",
    "* A1: Informed consent, A2: Collection bias, A3: Limit PII exposure\n",
    "    * A.1 Informed consent: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "    * A.2 Collection bias: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "    * A.3 Limit PII exposure: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "For the following scenario, familiarize yourself with, then use this Data Science Ethics Checklist, (part of the open source deon command line tool) to choose the best answer.\n",
    "\n",
    "The data science team decides to bring in social media data as they have found that the creditworthiness of an applicant's friends is a good indicator of the applicant's own creditworthiness. Which set of ethical concerns is most relevant here?\n",
    "\n",
    "* C5: Auditability, E3: Concept drift\n",
    "    * C.5 Auditability: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "    * E.3 Concept drift: Do we test and monitor for concept drift to ensure the model remains fair over time?\n",
    "* E4: Unintended use, D3: Metric selection\n",
    "    * E.4 Unintended use: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "    * D.3 Metric selection: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?    \n",
    "* **C2: Dataset bias, D2: Fairness across groups**\n",
    "    * C.2 Dataset bias: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "    * D.2 Fairness across groups: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Data ethics: With great power comes great responsibility. Part of the responsibilities of a data scientist includes thinking about the ethical implications of your work, such as was discussed during the MPP course. It is therefore important to be able to spot when different ethical issues may arise.\n",
    "\n",
    "For the following scenario, familiarize yourself with, then use this Data Science Ethics Checklist, (part of the open source deon command line tool) to find the most relevant ethical concerns.\n",
    "\n",
    "A bank wants to improve its creditworthiness assessment and decides to hire a team of data scientists to build an algorithm to predict the likelihood that an applicant will default on their loan. The data science team finds that whether or not a loan applicant graduated from a highly selective college is a good predictor of loan default. If this feature is used in the bank's algorithm, which ethical concern is most salient?\n",
    "\n",
    "* **D1: Proxy discrimination**\n",
    "    * D.1 Proxy discrimination: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "* C3: Honest representation\n",
    "    * C.3 Honest representation: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "* E4: Unintended use\n",
    "    * E.4 Unintended use: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "* B1: Data security\n",
    "    * B.1 Data security: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
